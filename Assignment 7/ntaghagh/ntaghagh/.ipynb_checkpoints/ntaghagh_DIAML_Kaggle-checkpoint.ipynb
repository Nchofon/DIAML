{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbe6a793",
   "metadata": {},
   "source": [
    "# Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af352620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all neccesary libraries\n",
    "# %pip install pandas scikit-learn\n",
    "\n",
    "import pandas as pd # Pandas\n",
    "import numpy as np # Numpy\n",
    "from scipy import stats # Scipy - for statistics\n",
    "import matplotlib.pyplot as plt # Matplotlib - for ploting\n",
    "import seaborn as sns # Seaborn - for ploting\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from tabulate import tabulate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced7ab4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_train_df = pd.read_csv('train.csv')\n",
    "kaggle_test_df = pd.read_csv('test.csv')\n",
    "\n",
    "kaggle_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60730eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_train_df = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "kaggle_train_df = kaggle_train_df[['Age', 'Sex', 'Pclass', 'Survived']]\n",
    "kaggle_train_df['Sex'] = kaggle_train_df['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "test_data = test_data[['Age', 'Sex', 'Pclass']]\n",
    "test_data['Sex'] = test_data['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "#kaggle_train_df = pd.get_dummies(kaggle_train_df, columns=['Pclass'], drop_first=True)\n",
    "kaggle_train_df['Age'] = kaggle_train_df['Age'].fillna(kaggle_train_df['Age'].mean())\n",
    "\n",
    "X = kaggle_train_df.drop(columns=['Survived'])\n",
    "y = kaggle_train_df['Survived']\n",
    "X_test = test_data[['Age', 'Sex', 'Pclass']]\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=24)\n",
    "\n",
    "# aggle_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b785222",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dd41a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF accuracy 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier \n",
    "\n",
    "leaves = range(2, 1000, 50)\n",
    "leave_accuracies = []\n",
    "\n",
    "for leaf in leaves:\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_leaf_nodes=leaf, random_state=16)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    #print(f'Leaf Nodes: {leaf}, Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    leave_accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "best_leave = leaves[np.argmax(leave_accuracies)]\n",
    "\n",
    "# Best tree with max_leaf_nodes\n",
    "num_trees = range(1, 1000, 50)\n",
    "tree_accuracies = []\n",
    "\n",
    "for tree in num_trees:\n",
    "    rf = RandomForestClassifier(n_estimators=tree, max_leaf_nodes=best_leave, random_state=16)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    #print(f'Number of Trees: {tree}, Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    tree_accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "best_tree = num_trees[np.argmax(tree_accuracies)]\n",
    "\n",
    "# Best Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=best_tree, max_leaf_nodes=best_leave, random_state=24)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Apply the same transformations to the test data\n",
    "test_data = pd.read_csv('test.csv')\n",
    "test_data = test_data[['Age', 'Sex', 'Pclass']]\n",
    "test_data['Sex'] = test_data['Sex'].map({'male': 0, 'female': 1})\n",
    "test_data['Age'] = test_data['Age'].fillna(test_data['Age'].mean())\n",
    "\n",
    "# Ensure the same dummy variables for Pclass in both training and test data\n",
    "test_data = pd.get_dummies(test_data, columns=['Pclass'])\n",
    "missing_cols = set(X.columns) - set(test_data.columns)\n",
    "for col in missing_cols:\n",
    "    test_data[col] = 0\n",
    "test_data = test_data[X.columns]\n",
    "\n",
    "y_pred = rf.predict(test_data)\n",
    "\n",
    "print('RF accuracy', max(tree_accuracies))\n",
    "print('Mean squared error: %.2f' % np.mean((rf.predict(X_test) - y_test) ** 2))\n",
    "# Output the results\n",
    "d_test = pd.read_csv('test.csv')\n",
    "pID = d_test['PassengerId']\n",
    "output = pd.DataFrame({'PassengerId': pID, 'Survived': y_pred})\n",
    "output.to_csv('submission_rf.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f02b73f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximimum tree and leaf nodes: 51 2\n"
     ]
    }
   ],
   "source": [
    "print('Maximimum tree and leaf nodes:', best_tree, best_leave)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce157e54",
   "metadata": {},
   "source": [
    "# Decission Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b201a578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for decision tree: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree \n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Choosing the best depth\n",
    "max_depth = range(1, 21)\n",
    "dt_accuracy= []\n",
    "\n",
    "for depth in max_depth:\n",
    "    dt = DecisionTreeClassifier(max_depth=depth)\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    dt_accuracy.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "dt_best_depth = max_depth[np.argmax(dt_accuracy)]\n",
    "dt_best = DecisionTreeClassifier(max_depth=dt_best_depth)\n",
    "dt_best.fit(X_train, y_train)\n",
    "print(\"Score for decision tree:\", dt_best.score(X_test, y_test))\n",
    "\n",
    "d_test = pd.read_csv('test.csv')\n",
    "pID = d_test['PassengerId']\n",
    "y_pred = dt_best.predict(test_data)\n",
    "output = pd.DataFrame({'PassengerId': pID, 'Survived': y_pred})\n",
    "output.to_csv('submission_dt.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db438ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print('Best depth',dt_best_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaa5630",
   "metadata": {},
   "source": [
    "# Logistic Regresion    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45046f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for logistic regression: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000, random_state=16)\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Score for logistic regression:\", lr.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d4c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC annalysis for logistic regression, random forest and decision tree\n",
    "y_pred = lr.predict(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ae7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Randome Forest Ensemble\n",
    "rf = RandomForestClassifier(n_estimators=950, max_depth=50, random_state=24)\n",
    "gbc = GradientBoostingClassifier(n_estimators=950, max_depth=5, random_state=24)\n",
    "lr = LogisticRegression(max_iter=1000, random_state=24)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "Voting = VotingClassifier(estimators=[('rf', rf), ('gbc', gbc), ('lr', lr), ('knn', knn)], voting='hard')\n",
    "\n",
    "Voting.fit(X_train, y_train)\n",
    "gbc.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "lr.fit(X_train, y_train)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Model hyperparameter tuning\n",
    "m_rf = RandomForestClassifier(random_state=24)\n",
    "param_grid = { 'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "                'max_depth': [50, 100, 150, 200, 250, 300, 350, 400, 450, 500],\n",
    "                'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'bootstrap': [True, False]}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(m_rf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
